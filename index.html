<html><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>A Lightweight One-Stage Framework for Fast and Realistic Face Swapping</title>
    <link rel="stylesheet" href="w3.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    <meta name="google-site-verification" content="vIrKe6Ecwa3TVjmMt0OaJpDGw_SJa5IxzTA86wU44QE">
</head>

<body data-new-gr-c-s-check-loaded="14.1043.0" data-gr-ext-installed="">

<br>
<br>

<div class="w3-container" id="paper">
    <div class="w3-content" style="max-width:800px">
  
    <h2 align="center" id="title"><b>A Lightweight One-Stage Framework for Fast and Realistic Face Swapping</b></h2>
    <br>

    <!-- <p align="center" id="title">WACV, 2023.</p> -->

    <p align="center" class="center_text" id="authors">
        Anonymous Authors
         
<!--         
        Sahng-Min Yoo<sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        Tae-Min Choi<sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        Jae-Woo Choi<sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        Jong-Hwan Kim<sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp; -->
    </p>

    <!-- <p class="center_text" align="center">
        <sup>1</sup><a href="http://rit.kaist.ac.kr">Robot Intelligence Technology Lab</a>, School of Electrical Engineering, <br>
        Korea Advanced Institute of Scien and Technology (KAIST)
    </p> -->
    <img src="first.png" width="800" align="middle">
        
    <img src="source1.png" width="125" align="middle"> <img src="target1.gif"  width="125" align="middle"> <img src="result1.gif"  width="125" align="middle"> <img src="source2.jpg"  width="125" align="middle"> <img src="target2.gif"  width="125" align="middle"> <img src="result2.gif"  width="125" align="middle">
    <img src="xxx.png" width="750" align="middle">
      
    <br>
    <!-- <font size="2"> 
        The face in the target image is replaced by the face in the source image. 
        All results are generated by our end-to-end model HifiFace-512. 
        If you want to see more celebrity demos, please refer to our supplementary material.
    </font> -->
    <br>
    <br>
    <br>
<!--         <h4 align="center" id="title"><b>Submit to our ScanRefer Localization Benchmark <a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/" target="__blank">here</a>!</b></h4>
        <br><center><a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/" target="__blank"><img src="teaser.png" style="max-width:100%" /></a></center><br> -->

        
        <h3 class="w3-left-align" id="video"><b>Abstract</b></h3>
        <hr>
        <p>
            Recent face swapping frameworks have achieved high-fidelity results. However, the previous works suffer from high computation costs due to the deep structure and the use of off-the-shelf networks. To overcome such problems and achieve real-time face swapping, we propose a lightweight one-stage framework FastSwap. We design a shallow network trained in a self-supervised manner without any manual annotations.
The core of our framework is a novel decoder block, called Triple Adaptive Normalization (TAN) block, which effectively integrates the identity and pose information. Besides, we propose a novel data augmentation and switch-test strategy to extract the attributes from the target image, which further enables controllable attribute editing. Extensive experiments on VoxCeleb2 and wild faces demonstrate that our framework generates high-fidelity face swapping results in 123.22 FPS and better preserves the identity, pose, and attributes than other state-of-the-art methods. Furthermore, we conduct an in-depth study to demonstrate the effectiveness of our proposal. Refer to our project webpage to make your own face swapping results and view additional results.
<!--             <img src="model.png" width="800" align="middle"> -->
            <table>
              <tr>
                  
<!--                       <figure> -->
                  <td><img alt="" src="overall_train2.png" width=585px /></td>
<!--                           <figcaption> (a) Overall Structure </figcaption> -->
<!--                       </figure> -->
                  <td><img alt="" src="train_test_example.png" width=215px/></td>
              <tr>
            </table>
            
            <div style="text-align : center;">
                <img src="tan_block.png" width="400">
            </div>
        </p>
        
        <br> 
        
        <h3 class="w3-left-align" id="video"><b>Additional Results</b></h3>
        <hr>
        <h5 class="w3-left-align" id="video"><b>Qualitative results</b></h5>
        <p>
            <img src="additional.png" width="800" align="middle">
        </p>

        <br>
        <h5 class="w3-left-align" id="video"><b>Switch-Test results</b></h5>
        <p>
            <img src="additional2.png" width="800" align="middle">
        </p>
        
        <br>
        <p>
            <img src="additional3.png" width="800" align="middle">
        </p>
        <h3 class="w3-left-align" id="video"><b>Do It Yourself &#128540;</b></h3>
        <hr>
        <p>
            Use the FastSwap to create your own creative and fun contents! <br>
            Please visit our <a href="http://13.209.73.27:3000/">FastSwap demo</a>. <br>
        </p>

        <br>

        <!-- <h3 class="w3-left-align" id="video"><b>Videos</b></h3>
        <hr>
        <table><tbody><tr>
            <td>
                <center><b>1-min Presentation Video</b></center>
                <p>
                        <iframe width="850" height="480" src="https://www.youtube.com/embed/T9J5t-UEcNA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    
                    <video width="424" height="238" controls="controls" autoplay=""> 
                        <source src="1min_video.mov">
                        Your browser does not support HTML-5. 
                    </video>       
                </p><p>
            </p></td>
            <td>
                <center><b>Selected Video from FF++</b></center>
                <p>
                        <iframe width="850" height="480" src="https://www.youtube.com/embed/T9J5t-UEcNA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                
                    <video width="424" height="238" controls="controls" autoplay=""> 
                        <source src="191_188_h264.mp4" type="video/mp4">
                        Your browser does not support HTML-5. 
                    </video>       
                </p><p>
            </p></td>
        </tr></tbody></table>
        <br> -->

    <h3 class="w3-left-align" id="publication"><b>Publication</b></h3>
    <hr>
    <!-- 30th International Joint Conference on Artificial Intelligence (IJCAI-21). <br/> -->
    <!--    <a href="davezchen_eccv2020_scanrefer.pdf" target="__blank">Paper</a>  -->


        <!-- Paper - <a href="https://arxiv.org/pdf/2106.09965" target="__blank">ArXiv - pdf</a> (<a href="https://arxiv.org/abs/2106.09965" target="__blank">abs</a>)  
        <br> -->
        <!--
        <center>
            <a href="https://arxiv.org/pdf/2106.09965" target="__blank"><img src="thumbnail.png" style="max-width:80%" /></a>
        </center><br>
        -->
    <!-- booktitle = {Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, {IJCAI-21}}, -->
    <!-- publisher = {International Joint Conferences on Artificial Intelligence Organization}, -->
    <!-- editor    = {Zhi-Hua Zhou}, -->
    <!-- pages     = {1136--1142}, -->
    <!-- month     = {8}, -->
    <!-- note      = {Main Track} -->
    <!-- doi       = {10.24963/ijcai.2021/157}, -->
    <!-- url       = {https://doi.org/10.24963/ijcai.2021/157}, -->
        <!-- If you find our work useful, please consider citing it: <br> -->
        Submitted to WACV 2023
        <!-- <table>
            <tbody><tr>
                <td>
                    <center>
                        <img src="1st page.png" style="max-width:100%">
                    </center>
                </td>
                <td>
                    <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 11px">@inproceedings{ijcai2022-1036,
    title     = {FastSwap: Fast and Realistic Face Swapping with Triple Adaptive Normalization},
    author    = {Sahng-Min Yoo, Tae-Min Choi, Jae-Woo Choi and Jong-Hwan Kim},
    year      = {2022},
}
                    </pre>
                </td>
            </tr>
        </tbody></table> -->
        
    <br>
    
    <!-- <h3 class="w3-left-align" id="dataset"><b>FaceForensics++</b></h3>
    <hr>
    We have prepared 1000 fake videos of well-known forgery detection dataset FaceForensics++. We strictly follow the source and target pair settings of FF++. Besides, we also generated 10k frames of FF++ videos for quantitative test, which is widely adopted by recent face swapping research. <br>
    <br>
    If you would like to access our FF++ videos, you can download them from either Google Drive or Baidu Netdisk. <br>
    <br>
        <h5 class="w3-left-align">Baidu Netdisk</h5>
        <ul>
            <li>Download all six splices from <a href="https://pan.baidu.com/s/1J_ZYWPI_-2CVUzXoL3sXjg">this link</a> with extraction code <b>nszb</b></li>
            <li>
                Concat these splices to form a compressed file and unzip it:
                <pre>cat FF++_HifiFace_* &gt;FF++_HifiFace.tar.gz
tar -xzvf FF++_HifiFace.tar.gz
                </pre>
            </li>
        </ul>
        
        <h5 class="w3-left-align">Google Drive</h5>
        <ul>
            <li>Download the compressed file from <a href="https://drive.google.com/file/d/10Jy9iEJHkNnkvpBA32246ViA9aHmv8KT/view?usp=sharing">this link</a> </li>
            <li>
                Unzip this file:
                <pre>tar -xzvf FF++_HifiFace.tar.gz                    
                </pre>
            </li>
        </ul>
    
    The md5sum of the compressed file is 5b596ac8025c25f69f24fd7783ec8133. It contains 1k manipulated videos and a config file. The config file indicates which frame of the original video is used as the identity's source image. The frame is numbered from zero. -->
    <br>
    <!-- If you encounter any problems or have anything else to ask, please contact us directly by email: 
    <a href="smyoo@rit.kaist.ac.kr">smyoo@rit.kaist.ac.kr</a> -->

    </div>

<!--
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=dtQGEJKQZDbd1zM31udAG14pTqhRC1mBXb_LbrXdMg8&cl=ffffff&w=a"></script>
-->

</div>

<br>
<br>



</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
